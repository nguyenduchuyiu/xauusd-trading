{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11294529,"sourceType":"datasetVersion","datasetId":7055460},{"sourceId":413002,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":337140,"modelId":358116}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip install ta","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T18:34:54.424202Z","iopub.execute_input":"2025-05-26T18:34:54.424581Z","iopub.status.idle":"2025-05-26T18:34:57.544572Z","shell.execute_reply.started":"2025-05-26T18:34:54.424545Z","shell.execute_reply":"2025-05-26T18:34:57.543586Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: ta in /usr/local/lib/python3.11/dist-packages (0.11.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ta) (1.26.4)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from ta) (2.2.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->ta) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->ta) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->ta) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->ta) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->ta) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->ta) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->ta) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->ta) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->ta) (2025.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->ta) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->ta) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->ta) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->ta) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->ta) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->ta) (2024.2.0)\n","output_type":"stream"}],"execution_count":94},{"cell_type":"code","source":"# For prepare data\nimport os\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\n\nimport ta\nfrom ta import add_all_ta_features\nfrom ta.momentum import RSIIndicator, StochasticOscillator, WilliamsRIndicator\nfrom ta.volatility import BollingerBands, AverageTrueRange\nfrom ta.trend import MACD, ADXIndicator\n\nfrom tqdm import tqdm\n\n# For modeling\nimport math\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.utils.class_weight import compute_class_weight\n\nimport torch\nimport torch.nn as nn\nfrom torch import optim\nfrom torch.nn import TransformerEncoder, TransformerEncoderLayer\nfrom torch.utils.data import Dataset, DataLoader, Subset\nimport torch.nn.functional as F\n# from pytorch_optimizer import SAM","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-26T18:34:57.547004Z","iopub.execute_input":"2025-05-26T18:34:57.547349Z","iopub.status.idle":"2025-05-26T18:34:57.553997Z","shell.execute_reply.started":"2025-05-26T18:34:57.547314Z","shell.execute_reply":"2025-05-26T18:34:57.553142Z"}},"outputs":[],"execution_count":95},{"cell_type":"markdown","source":"# Prepare data","metadata":{}},{"cell_type":"code","source":"# 1. Hàm load data\ndef load_data(file_path):\n    df = pd.read_csv(file_path)\n    # Xử lý datetime\n    df['Datetime'] = pd.to_datetime(df['Date'] + ' ' + df['Time'])\n    df = df.sort_values('Datetime').drop(['Date', 'Time'], axis=1)\n    return df\n\ntrain_df = load_data(\"/kaggle/input/xauusd1m/dynamic_labeled_train.csv\")\nval_df = load_data(\"/kaggle/input/xauusd1m/dynamic_labeled_dev.csv\")\ntest_df = load_data(\"/kaggle/input/xauusd1m/dynamic_labeled_test.csv\")\n\n# train_df = train_df.loc[train_df['Datetime'].dt.year.isin(range(2018, 2021))]\n\ntrain_df.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T18:34:57.554873Z","iopub.execute_input":"2025-05-26T18:34:57.555121Z","iopub.status.idle":"2025-05-26T18:35:03.480289Z","shell.execute_reply.started":"2025-05-26T18:34:57.555078Z","shell.execute_reply":"2025-05-26T18:35:03.479373Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 3446549 entries, 0 to 3446548\nData columns (total 7 columns):\n #   Column    Dtype         \n---  ------    -----         \n 0   Open      float64       \n 1   High      float64       \n 2   Low       float64       \n 3   Close     float64       \n 4   Volume    int64         \n 5   Label     object        \n 6   Datetime  datetime64[ns]\ndtypes: datetime64[ns](1), float64(4), int64(1), object(1)\nmemory usage: 184.1+ MB\n","output_type":"stream"}],"execution_count":96},{"cell_type":"code","source":"label_mapping = {\n    'BUY': 0,\n    'SELL': 1,\n    'HOLD': 2\n}\n\ndef map_label(x):\n    return label_mapping[x] if x in label_mapping else x\n\ntrain_df['Label'] = train_df['Label'].map(map_label)\nval_df['Label'] = val_df['Label'].map(map_label)\ntest_df['Label'] = test_df['Label'].map(map_label)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T18:35:03.482098Z","iopub.execute_input":"2025-05-26T18:35:03.482340Z","iopub.status.idle":"2025-05-26T18:35:05.086729Z","shell.execute_reply.started":"2025-05-26T18:35:03.482321Z","shell.execute_reply":"2025-05-26T18:35:05.086136Z"}},"outputs":[],"execution_count":97},{"cell_type":"code","source":"def add_technical_indicators(df):\n    \"\"\"Thêm các chỉ báo kỹ thuật.\"\"\"\n    print(\"Thêm các chỉ báo kỹ thuật...\")\n    # Momentum\n    df['RSI'] = ta.momentum.RSIIndicator(df['Close']).rsi()\n    df['Momentum'] = ta.momentum.ROCIndicator(df['Close']).roc()\n    df['CMO'] = ta.momentum.kama(df['Close'])\n    df['Williams_%R'] = ta.momentum.WilliamsRIndicator(df['High'], df['Low'], df['Close']).williams_r()\n    # Volatility\n    df['ATR'] = ta.volatility.AverageTrueRange(df['High'], df['Low'], df['Close']).average_true_range()\n    bb = ta.volatility.BollingerBands(df['Close'])\n    df['BB_Mid'] = bb.bollinger_mavg()\n    df['BB_Upper'] = bb.bollinger_hband()\n    df['BB_Lower'] = bb.bollinger_lband()\n    df['BB_Bandwidth'] = bb.bollinger_wband()\n    keltner = ta.volatility.KeltnerChannel(df['High'], df['Low'], df['Close'])\n    df['KC_High'] = keltner.keltner_channel_hband()\n    df['KC_Low'] = keltner.keltner_channel_lband()\n    donchian = ta.volatility.DonchianChannel(df['High'], df['Low'], df['Close'])\n    df['DC_High'] = donchian.donchian_channel_hband()\n    df['DC_Low'] = donchian.donchian_channel_lband()\n    # Trend\n    df['SMA_20'] = ta.trend.SMAIndicator(df['Close'], window=20).sma_indicator()\n    df['EMA_20'] = ta.trend.EMAIndicator(df['Close'], window=20).ema_indicator()\n    df['DPO'] = ta.trend.DPOIndicator(df['Close']).dpo()\n    macd = ta.trend.MACD(df['Close'])\n    df['MACD'] = macd.macd()\n    df['MACD_Hist'] = macd.macd_diff()\n    df['Mass_Index'] = ta.trend.mass_index(df['High'], df['Low'])\n    # Volume\n    df['AD'] = ta.volume.AccDistIndexIndicator(df['High'], df['Low'], df['Close'], df['Volume']).acc_dist_index()\n    df['CMF'] = ta.volume.ChaikinMoneyFlowIndicator(df['High'], df['Low'], df['Close'], df['Volume']).chaikin_money_flow()\n    df['Force_Index'] = ta.volume.ForceIndexIndicator(df['Close'], df['Volume']).force_index()\n    df['MFI'] = ta.volume.MFIIndicator(df['High'], df['Low'], df['Close'], df['Volume']).money_flow_index()\n    df['OBV'] = ta.volume.OnBalanceVolumeIndicator(df['Close'], df['Volume']).on_balance_volume()\n\n    print(\"Hoàn thành thêm chỉ báo.\")\n    return df.reset_index(drop=True)\n\ntrain_df = add_technical_indicators(train_df)\nval_df = add_technical_indicators(val_df)\ntest_df = add_technical_indicators(test_df)\n\ntrain_df.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T18:35:05.087808Z","iopub.execute_input":"2025-05-26T18:35:05.087994Z","iopub.status.idle":"2025-05-26T18:36:41.046318Z","shell.execute_reply.started":"2025-05-26T18:35:05.087980Z","shell.execute_reply":"2025-05-26T18:36:41.045253Z"}},"outputs":[{"name":"stdout","text":"Thêm các chỉ báo kỹ thuật...\nHoàn thành thêm chỉ báo.\nThêm các chỉ báo kỹ thuật...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater\n  return op(a, b)\n/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less\n  return op(a, b)\n/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater\n  return op(a, b)\n/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less\n  return op(a, b)\n/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less\n  return op(a, b)\n","output_type":"stream"},{"name":"stdout","text":"Hoàn thành thêm chỉ báo.\nThêm các chỉ báo kỹ thuật...\nHoàn thành thêm chỉ báo.\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 3446549 entries, 0 to 3446548\nData columns (total 31 columns):\n #   Column        Dtype         \n---  ------        -----         \n 0   Open          float64       \n 1   High          float64       \n 2   Low           float64       \n 3   Close         float64       \n 4   Volume        int64         \n 5   Label         int64         \n 6   Datetime      datetime64[ns]\n 7   RSI           float64       \n 8   Momentum      float64       \n 9   CMO           float64       \n 10  Williams_%R   float64       \n 11  ATR           float64       \n 12  BB_Mid        float64       \n 13  BB_Upper      float64       \n 14  BB_Lower      float64       \n 15  BB_Bandwidth  float64       \n 16  KC_High       float64       \n 17  KC_Low        float64       \n 18  DC_High       float64       \n 19  DC_Low        float64       \n 20  SMA_20        float64       \n 21  EMA_20        float64       \n 22  DPO           float64       \n 23  MACD          float64       \n 24  MACD_Hist     float64       \n 25  Mass_Index    float64       \n 26  AD            float64       \n 27  CMF           float64       \n 28  Force_Index   float64       \n 29  MFI           float64       \n 30  OBV           int64         \ndtypes: datetime64[ns](1), float64(27), int64(3)\nmemory usage: 815.1 MB\n","output_type":"stream"}],"execution_count":98},{"cell_type":"code","source":"def add_basic_features(df):\n    \"\"\"Tiền xử lý cuối: pct_change, ánh xạ nhãn, thêm đặc trưng thời gian.\"\"\"\n    print(\"Áp dụng tiền xử lý...\")\n    # Tính phần trăm thay đổi cho OHLC\n    cols_to_pct = ['Open', 'High', 'Low', 'Close']\n    existing_cols = [col for col in cols_to_pct if col in df.columns]\n    if existing_cols:\n        print(f\"Tính phần trăm thay đổi cho: {existing_cols}\")\n        df[existing_cols] = df[existing_cols].pct_change().fillna(0) * 100\n        df['Cum_Return'] = df['Close'].rolling(window=20).sum()\n        df['Cum_Turnover'] = df['Volume'].rolling(window=20).sum()\n    else:\n        print(\"Cảnh báo: Không tìm thấy cột OHLC để tính pct_change.\")\n\n    # Thêm đặc trưng thời gian\n    if 'Datetime' in df.columns:\n        print(\"Thêm đặc trưng thời gian (hour, day_of_week, minute_of_day, index)...\")\n        df['Hour'] = df['Datetime'].dt.hour / 23.0\n        df['Day_Of_Week'] = df['Datetime'].dt.dayofweek / 6.0\n        df['Minute_Of_Day'] = (df['Datetime'].dt.hour * 60 + df['Datetime'].dt.minute) / 1439.0\n        # df = df.drop(columns=['Datetime'], errors='ignore')\n    else:\n        print(\"Cảnh báo: Không thể tạo đặc trưng thời gian do thiếu cột 'Datetime'.\")\n\n    print(\"Hoàn thành tiền xử lý.\")\n    return df.reset_index(drop=True)\n\ntrain_df = add_basic_features(train_df)\nval_df = add_basic_features(val_df)\ntest_df = add_basic_features(test_df)\ntrain_df.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T18:36:41.047342Z","iopub.execute_input":"2025-05-26T18:36:41.047627Z","iopub.status.idle":"2025-05-26T18:36:43.493470Z","shell.execute_reply.started":"2025-05-26T18:36:41.047605Z","shell.execute_reply":"2025-05-26T18:36:43.492719Z"}},"outputs":[{"name":"stdout","text":"Áp dụng tiền xử lý...\nTính phần trăm thay đổi cho: ['Open', 'High', 'Low', 'Close']\nThêm đặc trưng thời gian (hour, day_of_week, minute_of_day, index)...\nHoàn thành tiền xử lý.\nÁp dụng tiền xử lý...\nTính phần trăm thay đổi cho: ['Open', 'High', 'Low', 'Close']\nThêm đặc trưng thời gian (hour, day_of_week, minute_of_day, index)...\nHoàn thành tiền xử lý.\nÁp dụng tiền xử lý...\nTính phần trăm thay đổi cho: ['Open', 'High', 'Low', 'Close']\nThêm đặc trưng thời gian (hour, day_of_week, minute_of_day, index)...\nHoàn thành tiền xử lý.\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 3446549 entries, 0 to 3446548\nData columns (total 36 columns):\n #   Column         Dtype         \n---  ------         -----         \n 0   Open           float64       \n 1   High           float64       \n 2   Low            float64       \n 3   Close          float64       \n 4   Volume         int64         \n 5   Label          int64         \n 6   Datetime       datetime64[ns]\n 7   RSI            float64       \n 8   Momentum       float64       \n 9   CMO            float64       \n 10  Williams_%R    float64       \n 11  ATR            float64       \n 12  BB_Mid         float64       \n 13  BB_Upper       float64       \n 14  BB_Lower       float64       \n 15  BB_Bandwidth   float64       \n 16  KC_High        float64       \n 17  KC_Low         float64       \n 18  DC_High        float64       \n 19  DC_Low         float64       \n 20  SMA_20         float64       \n 21  EMA_20         float64       \n 22  DPO            float64       \n 23  MACD           float64       \n 24  MACD_Hist      float64       \n 25  Mass_Index     float64       \n 26  AD             float64       \n 27  CMF            float64       \n 28  Force_Index    float64       \n 29  MFI            float64       \n 30  OBV            int64         \n 31  Cum_Return     float64       \n 32  Cum_Turnover   float64       \n 33  Hour           float64       \n 34  Day_Of_Week    float64       \n 35  Minute_Of_Day  float64       \ndtypes: datetime64[ns](1), float64(32), int64(3)\nmemory usage: 946.6 MB\n","output_type":"stream"}],"execution_count":99},{"cell_type":"code","source":"def drop_na_cols(df, threshold=0.01):\n    cnt = 0\n    for col in df.columns:\n        na = df[[col]].isna().sum()\n        if na.values > len(df) * threshold:\n            df.drop(col, axis=1, inplace=True)\n            cnt += 1\n    print(f'Deleted {cnt} cols')\n    return df\n\n# 6. Hàm xử lý missing values\ndef handle_missing_data(df, threshold=0.01):\n    df = drop_na_cols(df, threshold)\n    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n    \n    df = df.bfill().ffill()\n    df = df.dropna()\n    \n    return df\n\n# train_df\ntrain_df = handle_missing_data(train_df)\nval_df = handle_missing_data(val_df)\ntest_df = handle_missing_data(test_df)\ntrain_df.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T18:36:43.494279Z","iopub.execute_input":"2025-05-26T18:36:43.494554Z","iopub.status.idle":"2025-05-26T18:36:52.972872Z","shell.execute_reply.started":"2025-05-26T18:36:43.494530Z","shell.execute_reply":"2025-05-26T18:36:52.972145Z"}},"outputs":[{"name":"stdout","text":"Deleted 0 cols\nDeleted 0 cols\nDeleted 0 cols\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 3446549 entries, 0 to 3446548\nData columns (total 36 columns):\n #   Column         Dtype         \n---  ------         -----         \n 0   Open           float64       \n 1   High           float64       \n 2   Low            float64       \n 3   Close          float64       \n 4   Volume         int64         \n 5   Label          int64         \n 6   Datetime       datetime64[ns]\n 7   RSI            float64       \n 8   Momentum       float64       \n 9   CMO            float64       \n 10  Williams_%R    float64       \n 11  ATR            float64       \n 12  BB_Mid         float64       \n 13  BB_Upper       float64       \n 14  BB_Lower       float64       \n 15  BB_Bandwidth   float64       \n 16  KC_High        float64       \n 17  KC_Low         float64       \n 18  DC_High        float64       \n 19  DC_Low         float64       \n 20  SMA_20         float64       \n 21  EMA_20         float64       \n 22  DPO            float64       \n 23  MACD           float64       \n 24  MACD_Hist      float64       \n 25  Mass_Index     float64       \n 26  AD             float64       \n 27  CMF            float64       \n 28  Force_Index    float64       \n 29  MFI            float64       \n 30  OBV            int64         \n 31  Cum_Return     float64       \n 32  Cum_Turnover   float64       \n 33  Hour           float64       \n 34  Day_Of_Week    float64       \n 35  Minute_Of_Day  float64       \ndtypes: datetime64[ns](1), float64(32), int64(3)\nmemory usage: 946.6 MB\n","output_type":"stream"}],"execution_count":100},{"cell_type":"code","source":"def normalize_by_blocks(data, block_size):\n    print(f\"Áp dụng normalize_by_blocks với block_size={block_size}...\")\n    if isinstance(data, pd.DataFrame):\n        columns = data.columns\n        index = data.index\n        data_np = data.values.astype('float32')\n    else:\n        data_np = data.astype('float32')\n        columns = None\n        index = None\n\n    result = np.zeros_like(data_np)\n    num_blocks = 0\n\n    for start_idx in range(0, len(data_np), block_size):\n        end_idx = min(start_idx + block_size, len(data_np))\n        block = data_np[start_idx:end_idx]\n\n        if block.shape[0] > 0:\n            scaler = StandardScaler()\n            if block.shape[0] == 1:\n                normalized_block = block - np.mean(block, axis=0)\n            else:\n                std_devs = np.std(block, axis=0)\n                if np.any(std_devs == 0):\n                    normalized_block = np.zeros_like(block)\n                    valid_cols = std_devs != 0\n                    if np.any(valid_cols):\n                        scaler.fit(block[:, valid_cols])\n                        normalized_block[:, valid_cols] = scaler.transform(block[:, valid_cols])\n                    zero_std_cols = std_devs == 0\n                    if np.any(zero_std_cols):\n                        normalized_block[:, zero_std_cols] = block[:, zero_std_cols] - np.mean(block[:, zero_std_cols], axis=0)\n                else:\n                    normalized_block = scaler.fit_transform(block)\n\n            if np.isnan(normalized_block).any() or np.isinf(normalized_block).any():\n                normalized_block = np.nan_to_num(normalized_block, nan=0.0, posinf=0.0, neginf=0.0)\n\n            result[start_idx:end_idx] = normalized_block\n            num_blocks += 1\n\n    print(f\"Hoàn thành normalize_by_blocks. Đã xử lý {num_blocks} khối.\")\n    if columns is not None and index is not None:\n        return pd.DataFrame(result, columns=columns, index=index)\n    else:\n        return result\n\n# Định nghĩa các cột đặc trưng\nfeature_cols = [col for col in train_df.columns if col not in ['Label', 'Datetime']]\nprint(f\"Sử dụng {len(feature_cols)} cột đặc trưng: {feature_cols}\")\n\n# Áp dụng chuẩn hóa theo khối\nBLOCK_SIZE = 128\ntrain_df[feature_cols] = normalize_by_blocks(train_df[feature_cols], BLOCK_SIZE)\nval_df[feature_cols] = normalize_by_blocks(val_df[feature_cols], BLOCK_SIZE)\ntest_df[feature_cols] = normalize_by_blocks(test_df[feature_cols], BLOCK_SIZE)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T18:36:52.973846Z","iopub.execute_input":"2025-05-26T18:36:52.974267Z","iopub.status.idle":"2025-05-26T18:37:16.105219Z","shell.execute_reply.started":"2025-05-26T18:36:52.974241Z","shell.execute_reply":"2025-05-26T18:37:16.104470Z"}},"outputs":[{"name":"stdout","text":"Sử dụng 34 cột đặc trưng: ['Open', 'High', 'Low', 'Close', 'Volume', 'RSI', 'Momentum', 'CMO', 'Williams_%R', 'ATR', 'BB_Mid', 'BB_Upper', 'BB_Lower', 'BB_Bandwidth', 'KC_High', 'KC_Low', 'DC_High', 'DC_Low', 'SMA_20', 'EMA_20', 'DPO', 'MACD', 'MACD_Hist', 'Mass_Index', 'AD', 'CMF', 'Force_Index', 'MFI', 'OBV', 'Cum_Return', 'Cum_Turnover', 'Hour', 'Day_Of_Week', 'Minute_Of_Day']\nÁp dụng normalize_by_blocks với block_size=128...\nHoàn thành normalize_by_blocks. Đã xử lý 26927 khối.\nÁp dụng normalize_by_blocks với block_size=128...\nHoàn thành normalize_by_blocks. Đã xử lý 2743 khối.\nÁp dụng normalize_by_blocks với block_size=128...\nHoàn thành normalize_by_blocks. Đã xử lý 8808 khối.\n","output_type":"stream"}],"execution_count":101},{"cell_type":"code","source":"train_df.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T18:37:16.105968Z","iopub.execute_input":"2025-05-26T18:37:16.106222Z","iopub.status.idle":"2025-05-26T18:37:16.111808Z","shell.execute_reply.started":"2025-05-26T18:37:16.106204Z","shell.execute_reply":"2025-05-26T18:37:16.111137Z"}},"outputs":[{"execution_count":102,"output_type":"execute_result","data":{"text/plain":"Index(['Open', 'High', 'Low', 'Close', 'Volume', 'Label', 'Datetime', 'RSI',\n       'Momentum', 'CMO', 'Williams_%R', 'ATR', 'BB_Mid', 'BB_Upper',\n       'BB_Lower', 'BB_Bandwidth', 'KC_High', 'KC_Low', 'DC_High', 'DC_Low',\n       'SMA_20', 'EMA_20', 'DPO', 'MACD', 'MACD_Hist', 'Mass_Index', 'AD',\n       'CMF', 'Force_Index', 'MFI', 'OBV', 'Cum_Return', 'Cum_Turnover',\n       'Hour', 'Day_Of_Week', 'Minute_Of_Day'],\n      dtype='object')"},"metadata":{}}],"execution_count":102},{"cell_type":"code","source":"class PreprocessedStockDataset(Dataset):\n    def __init__(self, df, sequence_length, feature_cols, use_time2vec=True):\n        self.sequence_length = sequence_length\n        self.feature_cols = [col for col in feature_cols if col in df.columns]\n        self.use_time2vec = use_time2vec\n        self.has_time_input = False\n\n        print(f\"Khởi tạo PreprocessedStockDataset với {len(self.feature_cols)} đặc trưng.\")\n        if self.use_time2vec:\n            if \"Minute_Of_Day\" in df.columns and pd.api.types.is_numeric_dtype(df['Minute_Of_Day']):\n                print(\"Sử dụng 'minute_of_day' cho Time2Vec.\")\n                self.time_features = df[\"Minute_Of_Day\"].values[:, np.newaxis].astype(np.float32)\n                self.has_time_input = True\n            else:\n                print(\"Cảnh báo: Không tìm thấy 'minute_of_day'. Time2Vec sẽ dùng giá trị 0.\")\n                self.time_features = np.zeros((len(df), 1), dtype=np.float32)\n        else:\n            self.time_features = np.zeros((len(df), 1), dtype=np.float32)\n\n        self.features = df[self.feature_cols].values.astype(np.float32)\n        if 'Label' in df.columns and pd.api.types.is_numeric_dtype(df['Label']):\n            self.labels = df['Label'].values.astype(np.int64)\n            print(f\"Kích thước - Features: {self.features.shape}, Labels: {self.labels.shape}, Time: {self.time_features.shape}\")\n        else:\n            print(\"Cảnh báo: Không tìm thấy cột 'Label'. Tạo nhãn giả (0).\")\n            self.labels = np.zeros(len(df), dtype=np.int64)\n\n        if len(self.features) <= self.sequence_length:\n            raise ValueError(f\"Độ dài DataFrame ({len(self.features)}) phải lớn hơn sequence_length ({self.sequence_length}).\")\n\n    def __len__(self):\n        return len(self.features) - self.sequence_length\n\n    def __getitem__(self, idx):\n        end_idx = idx + self.sequence_length\n        feat_seq = self.features[idx:end_idx]\n        time_seq = self.time_features[idx:end_idx]\n        label = self.labels[end_idx]\n        return torch.from_numpy(feat_seq).float(), torch.from_numpy(time_seq).float(), torch.tensor(label).long()\n\n# Tạo Dataset\nUSE_TIME2VEC = True\nSEQ_LEN = 128\nprint(\"\\n--- Tạo Dataset và DataLoader ---\")\ntrain_dataset = PreprocessedStockDataset(train_df, SEQ_LEN, feature_cols, use_time2vec=USE_TIME2VEC)\nval_dataset = PreprocessedStockDataset(val_df, SEQ_LEN, feature_cols, use_time2vec=USE_TIME2VEC)\ntest_dataset = PreprocessedStockDataset(test_df, SEQ_LEN, feature_cols, use_time2vec=USE_TIME2VEC)\n\n# Tạo DataLoader\nBATCH_SIZE = 256\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=torch.cuda.is_available())\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE * 2, shuffle=False, num_workers=2, pin_memory=torch.cuda.is_available())\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE * 2, shuffle=False, num_workers=2, pin_memory=torch.cuda.is_available())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T18:37:16.114129Z","iopub.execute_input":"2025-05-26T18:37:16.114353Z","iopub.status.idle":"2025-05-26T18:37:16.885231Z","shell.execute_reply.started":"2025-05-26T18:37:16.114337Z","shell.execute_reply":"2025-05-26T18:37:16.884401Z"}},"outputs":[{"name":"stdout","text":"\n--- Tạo Dataset và DataLoader ---\nKhởi tạo PreprocessedStockDataset với 34 đặc trưng.\nSử dụng 'minute_of_day' cho Time2Vec.\nKích thước - Features: (3446549, 34), Labels: (3446549,), Time: (3446549, 1)\nKhởi tạo PreprocessedStockDataset với 34 đặc trưng.\nSử dụng 'minute_of_day' cho Time2Vec.\nKích thước - Features: (350984, 34), Labels: (350984,), Time: (350984, 1)\nKhởi tạo PreprocessedStockDataset với 34 đặc trưng.\nSử dụng 'minute_of_day' cho Time2Vec.\nKích thước - Features: (1127367, 34), Labels: (1127367,), Time: (1127367, 1)\n","output_type":"stream"}],"execution_count":103},{"cell_type":"code","source":"# Kiểm tra\nprint(\"Number of batches:\", len(train_loader))\nsample_batch = next(iter(train_loader))\nprint(\"Batch input shape:\", sample_batch[0].shape)\nprint(\"Batch times shape:\", sample_batch[1].shape)\nprint(\"Batch labels shape:\", sample_batch[2].shape)\nprint(\"\\nExample input shape for Transformer:\", sample_batch[0][0].shape)\nprint(sample_batch[0][0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T18:37:16.886034Z","iopub.execute_input":"2025-05-26T18:37:16.886332Z","iopub.status.idle":"2025-05-26T18:37:17.363514Z","shell.execute_reply.started":"2025-05-26T18:37:16.886313Z","shell.execute_reply":"2025-05-26T18:37:17.362609Z"}},"outputs":[{"name":"stdout","text":"Number of batches: 13463\nBatch input shape: torch.Size([256, 128, 34])\nBatch times shape: torch.Size([256, 128, 1])\nBatch labels shape: torch.Size([256])\n\nExample input shape for Transformer: torch.Size([128, 34])\ntensor([[ 0.6224,  0.8578,  0.7255,  ...,  0.9812,  0.0000,  0.7443],\n        [ 0.5433,  0.2644, -0.0107,  ...,  0.9812,  0.0000,  0.7713],\n        [-0.3728, -0.6069, -0.3159,  ...,  0.9812,  0.0000,  0.7984],\n        ...,\n        [-0.9408, -0.0384, -0.0298,  ...,  0.6713,  0.0000,  0.6631],\n        [ 0.5465, -0.0837,  0.2351,  ...,  0.6713,  0.0000,  0.6901],\n        [-0.2076, -0.5815, -2.3689,  ...,  0.6713,  0.0000,  0.7172]])\n","output_type":"stream"}],"execution_count":104},{"cell_type":"markdown","source":"# Modeling","metadata":{}},{"cell_type":"code","source":"class InceptionModule(nn.Module):\n    def __init__(self, in_channels):\n        super().__init__()\n        self.branch1 = nn.Conv1d(in_channels, 32, kernel_size=1, padding='same')\n        self.branch3 = nn.Conv1d(in_channels, 32, kernel_size=3, padding='same')\n        self.branch5 = nn.Conv1d(in_channels, 32, kernel_size=5, padding='same')\n        self.branch_pool = nn.Sequential(\n            nn.MaxPool1d(kernel_size=3, stride=1, padding=1),\n            nn.Conv1d(in_channels, 32, kernel_size=1)\n        )\n\n    def forward(self, x):\n        return torch.cat([self.branch1(x), self.branch3(x), self.branch5(x), self.branch_pool(x)], dim=1)\n\nclass Time2Vec(nn.Module):\n    def __init__(self, time_dim, kernel_dim=32):\n        super().__init__()\n        self.linear = nn.Linear(time_dim, 1)\n        self.periodic = nn.Linear(time_dim, kernel_dim - 1)\n\n    def forward(self, x):\n        linear = self.linear(x)\n        periodic = self.periodic(x)\n        return torch.cat([linear, periodic], dim=-1)\n\nclass CrossAttentionFusion(nn.Module):\n    def __init__(self, cnn_dim, transformer_dim):\n        super().__init__()\n        self.query = nn.Linear(cnn_dim, transformer_dim)\n        self.key = nn.Linear(transformer_dim, transformer_dim)\n        self.value = nn.Linear(transformer_dim, transformer_dim)\n        \n    def forward(self, cnn_features, transformer_features):\n        Q = self.query(cnn_features).unsqueeze(1)  # [batch, 1, transformer_dim]\n        K = self.key(transformer_features)         # [batch, seq_len, transformer_dim]\n        V = self.value(transformer_features)       # [batch, seq_len, transformer_dim]\n        \n        attn_scores = (Q @ K.transpose(-2, -1)) / (K.size(-1) ** 0.5)  # [batch, 1, seq_len]\n        attn_weights = torch.softmax(attn_scores, dim=-1)\n        \n        return torch.bmm(attn_weights, V).squeeze(1)  # [batch, transformer_dim]\n\nclass HighwayNetwork(nn.Module):\n    def __init__(self, d_model):\n        super().__init__()\n        self.gate = nn.Sequential(\n            nn.Linear(d_model, d_model),\n            nn.Sigmoid()\n        )\n        \n    def forward(self, fused, transformer):\n        g = self.gate(fused)\n        return g * fused + (1 - g) * transformer\n\nclass EnhancedHybridModel(nn.Module):\n    def __init__(self, num_features, time_dim, num_classes=3, d_model=512, nhead=16, dim_feedforward=1024, num_layers=6):\n        super().__init__()\n        # 1. InceptionTime Branch\n        self.inception = nn.Sequential(\n            InceptionModule(num_features),\n            nn.ReLU(),\n            nn.MaxPool1d(2),\n            InceptionModule(128),\n            nn.ReLU()\n        )\n        \n        # 2. Transformer Branch\n        self.time2vec = Time2Vec(time_dim, d_model//2)\n        self.transformer_proj = nn.Linear(num_features, d_model//2)\n        encoder_layer = nn.TransformerEncoderLayer(\n            d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward, batch_first=True\n        )\n        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n        \n        # 3. Fusion\n        self.cross_attention = CrossAttentionFusion(128, d_model)\n        self.highway = HighwayNetwork(d_model)\n        \n        # 4. Classifier\n        self.classifier = nn.Sequential(\n            nn.Linear(d_model, 128),\n            nn.LayerNorm(128),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(128, num_classes)\n        )\n\n    def forward(self, x, time_feature):\n        # 1. Inception Path\n        cnn_features = self.inception(x.permute(0, 2, 1))  # [batch, channels, seq_len//2]\n        cnn_features = cnn_features.mean(dim=-1)          # [batch, channels=128]\n        \n        # 2. Transformer Path\n        time_embed = self.time2vec(time_feature)  # [batch, seq_len, d_model // 2]\n        x_proj = self.transformer_proj(x)  # [batch, seq_len, d_model // 2]\n        combined = torch.cat([time_embed, x_proj], dim=-1) # [batch, seq_len, d_model]\n        transformer_features = self.transformer(combined)  # [batch, seq_len, d_model]\n        \n        # 3. Fusion\n        fused = self.cross_attention(cnn_features, transformer_features)  # [batch, d_model]\n        output = self.highway(fused, transformer_features.mean(dim=1))   # [batch, d_model]\n        \n        return self.classifier(output)\n\nN_FEATURES = sample_batch[0].shape[-1]\nmodel = EnhancedHybridModel(\n    num_features=N_FEATURES, time_dim=1, num_classes=3, \n    d_model=128, nhead=8, dim_feedforward=256, num_layers=3\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T18:37:17.364890Z","iopub.execute_input":"2025-05-26T18:37:17.365165Z","iopub.status.idle":"2025-05-26T18:37:17.392898Z","shell.execute_reply.started":"2025-05-26T18:37:17.365138Z","shell.execute_reply":"2025-05-26T18:37:17.392319Z"}},"outputs":[],"execution_count":105},{"cell_type":"code","source":"# print(model(sample_batch[0], sample_batch[1]).shape, sample_batch[2].shape)\n# from torchinfo import summary\n# print(summary(model, (BATCH_SIZE, SEQ_LEN, N_FEATURES)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T17:34:20.809521Z","iopub.status.idle":"2025-05-21T17:34:20.809810Z","shell.execute_reply.started":"2025-05-21T17:34:20.809679Z","shell.execute_reply":"2025-05-21T17:34:20.809691Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"class EarlyStopping:\n    def __init__(self, patience=3, min_delta=0.001, save_path='best_model.pth'):\n        \"\"\"\n        patience: Số epoch chờ mà không cải thiện trước khi dừng\n        min_delta: Độ cải thiện tối thiểu để coi là tốt hơn\n        \"\"\"\n        self.patience = patience\n        self.min_delta = min_delta\n        self.counter = 0\n        self.best_loss = None\n        self.early_stop = False\n        self.save_path = save_path\n\n    def __call__(self, model, val_loss):\n        if self.best_loss is None:\n            self.best_loss = val_loss\n        elif val_loss > self.best_loss - self.min_delta:\n            self.counter += 1\n            print(f'EarlyStopping counter: {self.counter}/{self.patience}')\n            if self.counter >= self.patience:\n                self.early_stop = True\n        else:\n            self.best_loss = val_loss\n            self.counter = 0\n            torch.save(model.state_dict(), self.save_path)\n            \ndef eval_model(model, val_loader, criterion, device):\n    model.to(device)\n    model.eval()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n\n    loop = tqdm(val_loader, unit='batch', desc='\\tEvaluating: ')\n    with torch.no_grad():\n        for i, (inputs, times, labels) in enumerate(loop):\n            inputs, times, labels = inputs.to(device), times.to(device), labels.to(device)\n            outputs = model(inputs, times)\n            loss = criterion(outputs, labels)\n            \n            running_loss += loss.item()\n            _, predicted = torch.max(outputs.data, -1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n            loop.set_postfix(loss=(running_loss / (i + 1)))\n    \n    epoch_loss = running_loss / len(val_loader)\n    epoch_acc = 100 * correct / total\n    \n    return epoch_loss, epoch_acc\n\ndef train_model(model, train_loader, criterion, optimizer, device):\n    model.to(device)\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    \n    loop = tqdm(train_loader, unit='batch', desc=f'\\tTraining: ')\n    for i, (inputs, times, labels) in enumerate(loop):\n        inputs, times, labels = inputs.to(device), times.to(device), labels.to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(inputs, times)\n        loss = criterion(outputs, labels)\n        \n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optimizer.step()\n        \n        running_loss += loss.item()\n        _, predicted = torch.max(outputs.data, -1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n        loop.set_postfix(loss=(running_loss / (i + 1)))\n    \n    epoch_loss = running_loss / len(train_loader)\n    epoch_acc = 100 * correct / total\n    \n    return epoch_loss, epoch_acc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T18:09:45.604417Z","iopub.execute_input":"2025-05-21T18:09:45.604864Z","iopub.status.idle":"2025-05-21T18:09:45.619313Z","shell.execute_reply.started":"2025-05-21T18:09:45.604828Z","shell.execute_reply":"2025-05-21T18:09:45.618441Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2, verbose=True)\n\nNUM_EPOCHS = 10\nPATIENCE = 10\nMIN_DELTA = 0.0001\nSAVE_PATH = 'best_model.pth'\ntorch.cuda.empty_cache()\n\n# model = nn.DataParallel(model)\n    \ntrain_losses = []\ntrain_accs = []\nval_losses = []\nval_accs = []\n\nearly_stopping = EarlyStopping(patience=PATIENCE, min_delta=MIN_DELTA, save_path=SAVE_PATH)\nfor epoch in range(NUM_EPOCHS):\n    print(f'Epoch [{epoch + 1}/{NUM_EPOCHS}]')\n    \n    train_loss, train_acc = train_model(model, train_loader, criterion, optimizer, DEVICE)\n    val_loss, val_acc = eval_model(model, val_loader, criterion, DEVICE)\n    \n    print(f'\\tTrain Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.2f}%')\n    print(f'\\tVal Loss: {val_loss:.4f}, Val Accuracy: {val_acc:.2f}%')\n    train_losses.append(train_loss)\n    train_accs.append(train_acc)\n    val_losses.append(val_loss)\n    val_accs.append(val_acc)\n    \n    scheduler.step(val_loss)\n    \n    # Kiểm tra Early Stopping\n    early_stopping(model, val_loss)\n    if early_stopping.early_stop:\n        print(\"Early stopping triggered!\")\n        break\n    print('===================================================')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T18:09:52.266110Z","iopub.execute_input":"2025-05-21T18:09:52.266848Z","iopub.status.idle":"2025-05-21T18:12:46.039277Z","shell.execute_reply.started":"2025-05-21T18:09:52.266822Z","shell.execute_reply":"2025-05-21T18:12:46.038242Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Evaluate","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\ndef plot_training_results(train_losses, train_accs, val_losses, val_accs):\n    \"\"\"\n    Vẽ biểu đồ kết quả huấn luyện: loss và accuracy cho train và validation.\n    \n    Parameters:\n    - train_losses: List các giá trị loss của train qua các epoch\n    - train_accs: List các giá trị accuracy của train qua các epoch\n    - val_losses: List các giá trị loss của validation qua các epoch\n    - val_accs: List các giá trị accuracy của validation qua các epoch\n    \"\"\"\n    epochs = range(1, len(train_losses) + 1)\n    \n    # Tạo figure với 2x2 subplot\n    plt.figure(figsize=(12, 8))\n    \n    # Subplot 1: Train Loss\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs, train_losses, 'b-', label='Train Loss')\n    plt.plot(epochs, val_losses, 'r-', label='Validation Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.title('Loss')\n    plt.legend()\n    plt.grid(True)\n    \n    # Subplot 2: Train Accuracy\n    plt.subplot(1, 2, 2)\n    plt.plot(epochs, train_accs, 'g-', label='Train Accuracy')\n    plt.plot(epochs, val_accs, 'm-', label='Validation Accuracy')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy (%)')\n    plt.title('Accuracy')\n    plt.legend()\n    plt.grid(True)\n    \n    # Điều chỉnh layout và hiển thị\n    plt.tight_layout()\n    plt.show()\n\nplot_training_results(train_losses, train_accs, val_losses, val_accs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T17:34:20.814828Z","iopub.status.idle":"2025-05-21T17:34:20.815134Z","shell.execute_reply.started":"2025-05-21T17:34:20.815014Z","shell.execute_reply":"2025-05-21T17:34:20.815027Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def test_model(model, data_loader, device='cuda' if torch.cuda.is_available() else 'cpu'):\n    model.to(device)\n    model.eval()\n\n    all_preds = []\n    all_labels = []\n\n    with torch.no_grad():\n        loop = tqdm(data_loader, unit='batch', desc=f'\\tEvaluate metrics: ')\n        for i, (inputs, times, labels) in enumerate(loop):\n            inputs, times, labels = inputs.to(device), times.to(device), labels.to(device)\n\n            outputs = model(inputs, times)  # Expecting [B, num_classes]\n            preds = torch.argmax(outputs, dim=-1)\n\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n    target_names = ['BUY', 'SELL', 'HOLD']\n    cm = confusion_matrix(all_labels, all_preds)\n    print('Confusion matrix:')\n    print(pd.DataFrame(cm, columns=target_names, index=target_names))\n    print(\"Classification Report:\")\n    print(classification_report(all_labels, all_preds, target_names=target_names, digits=4, zero_division=0))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T17:34:20.815808Z","iopub.status.idle":"2025-05-21T17:34:20.816098Z","shell.execute_reply.started":"2025-05-21T17:34:20.815928Z","shell.execute_reply":"2025-05-21T17:34:20.815940Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nSAVE_PATH = '/kaggle/input/inception-transformers-trading/pytorch/default/1/best_model (2).pth'\nmodel.load_state_dict(torch.load(SAVE_PATH, weights_only=True))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T18:37:27.489007Z","iopub.execute_input":"2025-05-26T18:37:27.489598Z","iopub.status.idle":"2025-05-26T18:37:27.523064Z","shell.execute_reply.started":"2025-05-26T18:37:27.489571Z","shell.execute_reply":"2025-05-26T18:37:27.522368Z"}},"outputs":[{"execution_count":106,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}],"execution_count":106},{"cell_type":"code","source":"test_model(model, train_loader, DEVICE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T17:34:20.817063Z","iopub.status.idle":"2025-05-21T17:34:20.817280Z","shell.execute_reply.started":"2025-05-21T17:34:20.817183Z","shell.execute_reply":"2025-05-21T17:34:20.817192Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_model(model, val_loader, DEVICE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T17:34:20.818866Z","iopub.status.idle":"2025-05-21T17:34:20.819135Z","shell.execute_reply.started":"2025-05-21T17:34:20.819017Z","shell.execute_reply":"2025-05-21T17:34:20.819029Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_model(model, test_loader, DEVICE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T17:34:20.820299Z","iopub.status.idle":"2025-05-21T17:34:20.820507Z","shell.execute_reply.started":"2025-05-21T17:34:20.820409Z","shell.execute_reply":"2025-05-21T17:34:20.820418Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class PreprocessedStockWithDatetimeDataset(Dataset):\n    def __init__(self, df, sequence_length, feature_cols, use_time2vec=True):\n        self.sequence_length = sequence_length\n        self.feature_cols = [col for col in feature_cols if col in df.columns]\n        self.use_time2vec = use_time2vec\n        self.has_time_input = False\n\n        print(f\"Khởi tạo PreprocessedStockDataset với {len(self.feature_cols)} đặc trưng.\")\n        if self.use_time2vec:\n            if \"Minute_Of_Day\" in df.columns and pd.api.types.is_numeric_dtype(df['Minute_Of_Day']):\n                print(\"Sử dụng 'minute_of_day' cho Time2Vec.\")\n                self.time_features = df[\"Minute_Of_Day\"].values[:, np.newaxis].astype(np.float32)\n                self.has_time_input = True\n            else:\n                print(\"Cảnh báo: Không tìm thấy 'minute_of_day'. Time2Vec sẽ dùng giá trị 0.\")\n                self.time_features = np.zeros((len(df), 1), dtype=np.float32)\n        else:\n            self.time_features = np.zeros((len(df), 1), dtype=np.float32)\n\n        self.features = df[self.feature_cols].values.astype(np.float32)\n        self.labels = df['Label'].values.astype(np.int64) if 'Label' in df.columns else np.zeros(len(df), dtype=np.int64)\n\n        if 'Datetime' in df.columns:\n            dt_parsed = pd.to_datetime(df['Datetime'], format=\"%Y-%m-%d %H:%M:%S\", errors='coerce').apply(encode_datetime)\n            self.datetimes = dt_parsed.values.astype(np.int64)\n        else:\n            self.datetimes = np.zeros(len(df), dtype=np.int64)\n\n        if len(self.features) <= self.sequence_length:\n            raise ValueError(f\"Độ dài DataFrame ({len(self.features)}) phải lớn hơn sequence_length ({self.sequence_length}).\")\n\n    def __len__(self):\n        return len(self.features) - self.sequence_length\n\n    def __getitem__(self, idx):\n        end_idx = idx + self.sequence_length\n        feat_seq = self.features[idx:end_idx]\n        time_seq = self.time_features[idx:end_idx]\n        label = self.labels[end_idx]\n        datetime_encoded = self.datetimes[end_idx]\n        return (\n            torch.from_numpy(feat_seq).float(), \n            torch.from_numpy(time_seq).float(), \n            torch.tensor(label).long(), \n            torch.tensor(datetime_encoded).long()\n        )\n\n\n\ndef encode_datetime(dt):\n    encoded_str = dt.strftime(\"%y%m%d%H%M\")\n    encoded_int = int(encoded_str)\n    return encoded_int\n\ndef decode_datetime(encoded_dt):\n    decoded_int = int(round(encoded_dt))\n    # decoded_str = str(decoded_int).zfill(10)  # Ensure leading 0s\n    decoded_str = str(decoded_int)\n    # print('------>', decoded_str)\n    return datetime.strptime(decoded_str, \"%y%m%d%H%M\")\n\ndef get_prediction(model, inputs, times, device):\n    # inputs = [B, S, N]\n    model.to(device)\n    model.eval()\n    with torch.no_grad():\n        inputs = inputs.to(device)\n        times = times.to(device)\n        outputs = model(inputs, times)\n        probs = torch.softmax(outputs, dim=-1)\n        probs, preds = torch.max(probs, dim=-1)\n    return preds.cpu().numpy(), probs.cpu().numpy()\n\ndef get_accuracy_per_batch(model, dataloader, device):\n    results = {\n        'BUY ACCURACY': [],\n        'SELL ACCURACY': [],\n        'HOLD ACCURACY': [],\n        'OVERALL ACCURACY': []\n    }\n    \n    loop = tqdm(dataloader, desc='Testing', unit='batch')\n    for (inputs, times, labels) in loop:\n        labels = labels.cpu().numpy()\n        preds, _ = get_prediction(model, inputs, times, device)\n    \n        buy_acc = ((labels == 0) == (preds == 0)).sum() / len(labels)\n        sell_acc = ((labels == 1) == (preds == 1)).sum() / len(labels)\n        hold_acc = ((labels == 2) == (preds == 2)).sum() / len(labels)\n        overall_acc = (labels == preds).sum() / len(labels)\n    \n        results['BUY ACCURACY'].append(buy_acc)\n        results['SELL ACCURACY'].append(sell_acc)\n        results['HOLD ACCURACY'].append(hold_acc)\n        results['OVERALL ACCURACY'].append(overall_acc)\n\n    return results\n\ndef convert2df(results, save_path):\n    results_df = pd.DataFrame(results)\n    results_df.to_csv(save_path, index=False)\n    return results_df\n\ndef generate_predictions(model, dataloader, device):\n    results = {\n        'DATETIME': [],\n        'GROUNDTRUTH': [],\n        'PREDICTION': [],\n        'PROBS': []\n    }\n    \n    loop = tqdm(dataloader, desc='Testing', unit='batch')\n    for (inputs, times, labels, datetimes) in loop:\n        labels = labels.cpu().numpy()\n        datetimes = datetimes.cpu().numpy()\n        preds, probs = get_prediction(model, inputs, times, device)\n\n        # Decode từ float back thành datetime object\n        datetimes_converted = [decode_datetime(float(dt)) for dt in datetimes]\n\n        results['DATETIME'].extend(datetimes_converted)\n        results['GROUNDTRUTH'].extend(labels)\n        results['PREDICTION'].extend(preds)\n        results['PROBS'].extend(probs)\n\n    return results\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T18:37:49.540587Z","iopub.execute_input":"2025-05-26T18:37:49.541120Z","iopub.status.idle":"2025-05-26T18:37:49.557971Z","shell.execute_reply.started":"2025-05-26T18:37:49.541095Z","shell.execute_reply":"2025-05-26T18:37:49.557378Z"}},"outputs":[],"execution_count":108},{"cell_type":"code","source":"train_results_df = convert2df(get_accuracy_per_batch(model, train_loader, DEVICE), 'train_acc_per_batch.csv')\nval_results_df = convert2df(get_accuracy_per_batch(model, val_loader, DEVICE), 'val_acc_per_batch.csv')\ntest_results_df = convert2df(get_accuracy_per_batch(model, test_loader, DEVICE), 'test_acc_per_batch.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T14:42:09.815618Z","iopub.execute_input":"2025-05-26T14:42:09.816306Z","iopub.status.idle":"2025-05-26T14:47:52.277888Z","shell.execute_reply.started":"2025-05-26T14:42:09.816282Z","shell.execute_reply":"2025-05-26T14:47:52.277145Z"}},"outputs":[{"name":"stderr","text":"Testing: 100%|██████████| 13463/13463 [04:06<00:00, 54.65batch/s]\nTesting: 100%|██████████| 686/686 [00:22<00:00, 29.91batch/s]\nTesting: 100%|██████████| 2202/2202 [01:13<00:00, 30.14batch/s]\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"# Tạo Dataset\nUSE_TIME2VEC = True\nSEQ_LEN = 128\nprint(\"\\n--- Tạo Dataset và DataLoader ---\")\ntrain_dataset = PreprocessedStockWithDatetimeDataset(train_df, SEQ_LEN, feature_cols, use_time2vec=USE_TIME2VEC)\nval_dataset = PreprocessedStockWithDatetimeDataset(val_df, SEQ_LEN, feature_cols, use_time2vec=USE_TIME2VEC)\ntest_dataset = PreprocessedStockWithDatetimeDataset(test_df, SEQ_LEN, feature_cols, use_time2vec=USE_TIME2VEC)\n\nBATCH_SIZE = 256\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE * 2, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE * 2, shuffle=False)\n\n\n# sample = next(iter(train_loader))\n# datetimes = sample[3].cpu().numpy()\n# for dt in datetimes:\n#     print(decode_datetime(dt))\n\ntrain_predictions = convert2df(generate_predictions(model, train_loader, DEVICE), 'train_predictions.csv')\nval_predictions = convert2df(generate_predictions(model, val_loader, DEVICE), 'val_predictions.csv')\ntest_predictions = convert2df(generate_predictions(model, test_loader, DEVICE), 'test_predictions.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T18:38:48.254048Z","iopub.execute_input":"2025-05-26T18:38:48.254324Z","iopub.status.idle":"2025-05-26T18:48:26.302655Z","shell.execute_reply.started":"2025-05-26T18:38:48.254307Z","shell.execute_reply":"2025-05-26T18:48:26.302077Z"}},"outputs":[{"name":"stdout","text":"\n--- Tạo Dataset và DataLoader ---\nKhởi tạo PreprocessedStockDataset với 34 đặc trưng.\nSử dụng 'minute_of_day' cho Time2Vec.\nKhởi tạo PreprocessedStockDataset với 34 đặc trưng.\nSử dụng 'minute_of_day' cho Time2Vec.\nKhởi tạo PreprocessedStockDataset với 34 đặc trưng.\nSử dụng 'minute_of_day' cho Time2Vec.\n","output_type":"stream"},{"name":"stderr","text":"Testing: 100%|██████████| 13463/13463 [06:00<00:00, 37.29batch/s]\nTesting: 100%|██████████| 686/686 [00:35<00:00, 19.31batch/s]\nTesting: 100%|██████████| 2202/2202 [01:54<00:00, 19.24batch/s]\n","output_type":"stream"}],"execution_count":110},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}