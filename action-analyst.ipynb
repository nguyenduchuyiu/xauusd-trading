{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T18:34:54.424581Z",
     "iopub.status.busy": "2025-05-26T18:34:54.424202Z",
     "iopub.status.idle": "2025-05-26T18:34:57.544572Z",
     "shell.execute_reply": "2025-05-26T18:34:57.543586Z",
     "shell.execute_reply.started": "2025-05-26T18:34:54.424545Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ta in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ta) (1.26.4)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from ta) (2.2.3)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->ta) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->ta) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->ta) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->ta) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->ta) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->ta) (2.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->ta) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->ta) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->ta) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->ta) (1.17.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->ta) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->ta) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->ta) (1.3.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->ta) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->ta) (2024.2.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-26T18:34:57.547349Z",
     "iopub.status.busy": "2025-05-26T18:34:57.547004Z",
     "iopub.status.idle": "2025-05-26T18:34:57.553997Z",
     "shell.execute_reply": "2025-05-26T18:34:57.553142Z",
     "shell.execute_reply.started": "2025-05-26T18:34:57.547314Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# For prepare data\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import ta\n",
    "from ta import add_all_ta_features\n",
    "from ta.momentum import RSIIndicator, StochasticOscillator, WilliamsRIndicator\n",
    "from ta.volatility import BollingerBands, AverageTrueRange\n",
    "from ta.trend import MACD, ADXIndicator\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# For modeling\n",
    "import math\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import torch.nn.functional as F\n",
    "# from pytorch_optimizer import SAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T18:34:57.555121Z",
     "iopub.status.busy": "2025-05-26T18:34:57.554873Z",
     "iopub.status.idle": "2025-05-26T18:35:03.480289Z",
     "shell.execute_reply": "2025-05-26T18:35:03.479373Z",
     "shell.execute_reply.started": "2025-05-26T18:34:57.555078Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3446549 entries, 0 to 3446548\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Dtype         \n",
      "---  ------    -----         \n",
      " 0   Open      float64       \n",
      " 1   High      float64       \n",
      " 2   Low       float64       \n",
      " 3   Close     float64       \n",
      " 4   Volume    int64         \n",
      " 5   Label     object        \n",
      " 6   Datetime  datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(4), int64(1), object(1)\n",
      "memory usage: 184.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# 1. Hàm load data\n",
    "def load_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    # Xử lý datetime\n",
    "    df['Datetime'] = pd.to_datetime(df['Date'] + ' ' + df['Time'])\n",
    "    df = df.sort_values('Datetime').drop(['Date', 'Time'], axis=1)\n",
    "    return df\n",
    "\n",
    "train_df = load_data(\"/kaggle/input/xauusd1m/dynamic_labeled_train.csv\")\n",
    "val_df = load_data(\"/kaggle/input/xauusd1m/dynamic_labeled_dev.csv\")\n",
    "test_df = load_data(\"/kaggle/input/xauusd1m/dynamic_labeled_test.csv\")\n",
    "\n",
    "# train_df = train_df.loc[train_df['Datetime'].dt.year.isin(range(2018, 2021))]\n",
    "\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T18:35:03.482340Z",
     "iopub.status.busy": "2025-05-26T18:35:03.482098Z",
     "iopub.status.idle": "2025-05-26T18:35:05.086729Z",
     "shell.execute_reply": "2025-05-26T18:35:05.086136Z",
     "shell.execute_reply.started": "2025-05-26T18:35:03.482321Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "label_mapping = {\n",
    "    'BUY': 0,\n",
    "    'SELL': 1,\n",
    "    'HOLD': 2\n",
    "}\n",
    "\n",
    "def map_label(x):\n",
    "    return label_mapping[x] if x in label_mapping else x\n",
    "\n",
    "train_df['Label'] = train_df['Label'].map(map_label)\n",
    "val_df['Label'] = val_df['Label'].map(map_label)\n",
    "test_df['Label'] = test_df['Label'].map(map_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T18:35:05.087994Z",
     "iopub.status.busy": "2025-05-26T18:35:05.087808Z",
     "iopub.status.idle": "2025-05-26T18:36:41.046318Z",
     "shell.execute_reply": "2025-05-26T18:36:41.045253Z",
     "shell.execute_reply.started": "2025-05-26T18:35:05.087980Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thêm các chỉ báo kỹ thuật...\n",
      "Hoàn thành thêm chỉ báo.\n",
      "Thêm các chỉ báo kỹ thuật...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater\n",
      "  return op(a, b)\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less\n",
      "  return op(a, b)\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater\n",
      "  return op(a, b)\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less\n",
      "  return op(a, b)\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less\n",
      "  return op(a, b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hoàn thành thêm chỉ báo.\n",
      "Thêm các chỉ báo kỹ thuật...\n",
      "Hoàn thành thêm chỉ báo.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3446549 entries, 0 to 3446548\n",
      "Data columns (total 31 columns):\n",
      " #   Column        Dtype         \n",
      "---  ------        -----         \n",
      " 0   Open          float64       \n",
      " 1   High          float64       \n",
      " 2   Low           float64       \n",
      " 3   Close         float64       \n",
      " 4   Volume        int64         \n",
      " 5   Label         int64         \n",
      " 6   Datetime      datetime64[ns]\n",
      " 7   RSI           float64       \n",
      " 8   Momentum      float64       \n",
      " 9   CMO           float64       \n",
      " 10  Williams_%R   float64       \n",
      " 11  ATR           float64       \n",
      " 12  BB_Mid        float64       \n",
      " 13  BB_Upper      float64       \n",
      " 14  BB_Lower      float64       \n",
      " 15  BB_Bandwidth  float64       \n",
      " 16  KC_High       float64       \n",
      " 17  KC_Low        float64       \n",
      " 18  DC_High       float64       \n",
      " 19  DC_Low        float64       \n",
      " 20  SMA_20        float64       \n",
      " 21  EMA_20        float64       \n",
      " 22  DPO           float64       \n",
      " 23  MACD          float64       \n",
      " 24  MACD_Hist     float64       \n",
      " 25  Mass_Index    float64       \n",
      " 26  AD            float64       \n",
      " 27  CMF           float64       \n",
      " 28  Force_Index   float64       \n",
      " 29  MFI           float64       \n",
      " 30  OBV           int64         \n",
      "dtypes: datetime64[ns](1), float64(27), int64(3)\n",
      "memory usage: 815.1 MB\n"
     ]
    }
   ],
   "source": [
    "def add_technical_indicators(df):\n",
    "    \"\"\"Thêm các chỉ báo kỹ thuật.\"\"\"\n",
    "    print(\"Thêm các chỉ báo kỹ thuật...\")\n",
    "    # Momentum\n",
    "    df['RSI'] = ta.momentum.RSIIndicator(df['Close']).rsi()\n",
    "    df['Momentum'] = ta.momentum.ROCIndicator(df['Close']).roc()\n",
    "    df['CMO'] = ta.momentum.kama(df['Close'])\n",
    "    df['Williams_%R'] = ta.momentum.WilliamsRIndicator(df['High'], df['Low'], df['Close']).williams_r()\n",
    "    # Volatility\n",
    "    df['ATR'] = ta.volatility.AverageTrueRange(df['High'], df['Low'], df['Close']).average_true_range()\n",
    "    bb = ta.volatility.BollingerBands(df['Close'])\n",
    "    df['BB_Mid'] = bb.bollinger_mavg()\n",
    "    df['BB_Upper'] = bb.bollinger_hband()\n",
    "    df['BB_Lower'] = bb.bollinger_lband()\n",
    "    df['BB_Bandwidth'] = bb.bollinger_wband()\n",
    "    keltner = ta.volatility.KeltnerChannel(df['High'], df['Low'], df['Close'])\n",
    "    df['KC_High'] = keltner.keltner_channel_hband()\n",
    "    df['KC_Low'] = keltner.keltner_channel_lband()\n",
    "    donchian = ta.volatility.DonchianChannel(df['High'], df['Low'], df['Close'])\n",
    "    df['DC_High'] = donchian.donchian_channel_hband()\n",
    "    df['DC_Low'] = donchian.donchian_channel_lband()\n",
    "    # Trend\n",
    "    df['SMA_20'] = ta.trend.SMAIndicator(df['Close'], window=20).sma_indicator()\n",
    "    df['EMA_20'] = ta.trend.EMAIndicator(df['Close'], window=20).ema_indicator()\n",
    "    df['DPO'] = ta.trend.DPOIndicator(df['Close']).dpo()\n",
    "    macd = ta.trend.MACD(df['Close'])\n",
    "    df['MACD'] = macd.macd()\n",
    "    df['MACD_Hist'] = macd.macd_diff()\n",
    "    df['Mass_Index'] = ta.trend.mass_index(df['High'], df['Low'])\n",
    "    # Volume\n",
    "    df['AD'] = ta.volume.AccDistIndexIndicator(df['High'], df['Low'], df['Close'], df['Volume']).acc_dist_index()\n",
    "    df['CMF'] = ta.volume.ChaikinMoneyFlowIndicator(df['High'], df['Low'], df['Close'], df['Volume']).chaikin_money_flow()\n",
    "    df['Force_Index'] = ta.volume.ForceIndexIndicator(df['Close'], df['Volume']).force_index()\n",
    "    df['MFI'] = ta.volume.MFIIndicator(df['High'], df['Low'], df['Close'], df['Volume']).money_flow_index()\n",
    "    df['OBV'] = ta.volume.OnBalanceVolumeIndicator(df['Close'], df['Volume']).on_balance_volume()\n",
    "\n",
    "    print(\"Hoàn thành thêm chỉ báo.\")\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "train_df = add_technical_indicators(train_df)\n",
    "val_df = add_technical_indicators(val_df)\n",
    "test_df = add_technical_indicators(test_df)\n",
    "\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T18:36:41.047627Z",
     "iopub.status.busy": "2025-05-26T18:36:41.047342Z",
     "iopub.status.idle": "2025-05-26T18:36:43.493470Z",
     "shell.execute_reply": "2025-05-26T18:36:43.492719Z",
     "shell.execute_reply.started": "2025-05-26T18:36:41.047605Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Áp dụng tiền xử lý...\n",
      "Tính phần trăm thay đổi cho: ['Open', 'High', 'Low', 'Close']\n",
      "Thêm đặc trưng thời gian (hour, day_of_week, minute_of_day, index)...\n",
      "Hoàn thành tiền xử lý.\n",
      "Áp dụng tiền xử lý...\n",
      "Tính phần trăm thay đổi cho: ['Open', 'High', 'Low', 'Close']\n",
      "Thêm đặc trưng thời gian (hour, day_of_week, minute_of_day, index)...\n",
      "Hoàn thành tiền xử lý.\n",
      "Áp dụng tiền xử lý...\n",
      "Tính phần trăm thay đổi cho: ['Open', 'High', 'Low', 'Close']\n",
      "Thêm đặc trưng thời gian (hour, day_of_week, minute_of_day, index)...\n",
      "Hoàn thành tiền xử lý.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3446549 entries, 0 to 3446548\n",
      "Data columns (total 36 columns):\n",
      " #   Column         Dtype         \n",
      "---  ------         -----         \n",
      " 0   Open           float64       \n",
      " 1   High           float64       \n",
      " 2   Low            float64       \n",
      " 3   Close          float64       \n",
      " 4   Volume         int64         \n",
      " 5   Label          int64         \n",
      " 6   Datetime       datetime64[ns]\n",
      " 7   RSI            float64       \n",
      " 8   Momentum       float64       \n",
      " 9   CMO            float64       \n",
      " 10  Williams_%R    float64       \n",
      " 11  ATR            float64       \n",
      " 12  BB_Mid         float64       \n",
      " 13  BB_Upper       float64       \n",
      " 14  BB_Lower       float64       \n",
      " 15  BB_Bandwidth   float64       \n",
      " 16  KC_High        float64       \n",
      " 17  KC_Low         float64       \n",
      " 18  DC_High        float64       \n",
      " 19  DC_Low         float64       \n",
      " 20  SMA_20         float64       \n",
      " 21  EMA_20         float64       \n",
      " 22  DPO            float64       \n",
      " 23  MACD           float64       \n",
      " 24  MACD_Hist      float64       \n",
      " 25  Mass_Index     float64       \n",
      " 26  AD             float64       \n",
      " 27  CMF            float64       \n",
      " 28  Force_Index    float64       \n",
      " 29  MFI            float64       \n",
      " 30  OBV            int64         \n",
      " 31  Cum_Return     float64       \n",
      " 32  Cum_Turnover   float64       \n",
      " 33  Hour           float64       \n",
      " 34  Day_Of_Week    float64       \n",
      " 35  Minute_Of_Day  float64       \n",
      "dtypes: datetime64[ns](1), float64(32), int64(3)\n",
      "memory usage: 946.6 MB\n"
     ]
    }
   ],
   "source": [
    "def add_basic_features(df):\n",
    "    \"\"\"Tiền xử lý cuối: pct_change, ánh xạ nhãn, thêm đặc trưng thời gian.\"\"\"\n",
    "    print(\"Áp dụng tiền xử lý...\")\n",
    "    # Tính phần trăm thay đổi cho OHLC\n",
    "    cols_to_pct = ['Open', 'High', 'Low', 'Close']\n",
    "    existing_cols = [col for col in cols_to_pct if col in df.columns]\n",
    "    if existing_cols:\n",
    "        print(f\"Tính phần trăm thay đổi cho: {existing_cols}\")\n",
    "        df[existing_cols] = df[existing_cols].pct_change().fillna(0) * 100\n",
    "        df['Cum_Return'] = df['Close'].rolling(window=20).sum()\n",
    "        df['Cum_Turnover'] = df['Volume'].rolling(window=20).sum()\n",
    "    else:\n",
    "        print(\"Cảnh báo: Không tìm thấy cột OHLC để tính pct_change.\")\n",
    "\n",
    "    # Thêm đặc trưng thời gian\n",
    "    if 'Datetime' in df.columns:\n",
    "        print(\"Thêm đặc trưng thời gian (hour, day_of_week, minute_of_day, index)...\")\n",
    "        df['Hour'] = df['Datetime'].dt.hour / 23.0\n",
    "        df['Day_Of_Week'] = df['Datetime'].dt.dayofweek / 6.0\n",
    "        df['Minute_Of_Day'] = (df['Datetime'].dt.hour * 60 + df['Datetime'].dt.minute) / 1439.0\n",
    "        # df = df.drop(columns=['Datetime'], errors='ignore')\n",
    "    else:\n",
    "        print(\"Cảnh báo: Không thể tạo đặc trưng thời gian do thiếu cột 'Datetime'.\")\n",
    "\n",
    "    print(\"Hoàn thành tiền xử lý.\")\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "train_df = add_basic_features(train_df)\n",
    "val_df = add_basic_features(val_df)\n",
    "test_df = add_basic_features(test_df)\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T18:36:43.494554Z",
     "iopub.status.busy": "2025-05-26T18:36:43.494279Z",
     "iopub.status.idle": "2025-05-26T18:36:52.972872Z",
     "shell.execute_reply": "2025-05-26T18:36:52.972145Z",
     "shell.execute_reply.started": "2025-05-26T18:36:43.494530Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted 0 cols\n",
      "Deleted 0 cols\n",
      "Deleted 0 cols\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3446549 entries, 0 to 3446548\n",
      "Data columns (total 36 columns):\n",
      " #   Column         Dtype         \n",
      "---  ------         -----         \n",
      " 0   Open           float64       \n",
      " 1   High           float64       \n",
      " 2   Low            float64       \n",
      " 3   Close          float64       \n",
      " 4   Volume         int64         \n",
      " 5   Label          int64         \n",
      " 6   Datetime       datetime64[ns]\n",
      " 7   RSI            float64       \n",
      " 8   Momentum       float64       \n",
      " 9   CMO            float64       \n",
      " 10  Williams_%R    float64       \n",
      " 11  ATR            float64       \n",
      " 12  BB_Mid         float64       \n",
      " 13  BB_Upper       float64       \n",
      " 14  BB_Lower       float64       \n",
      " 15  BB_Bandwidth   float64       \n",
      " 16  KC_High        float64       \n",
      " 17  KC_Low         float64       \n",
      " 18  DC_High        float64       \n",
      " 19  DC_Low         float64       \n",
      " 20  SMA_20         float64       \n",
      " 21  EMA_20         float64       \n",
      " 22  DPO            float64       \n",
      " 23  MACD           float64       \n",
      " 24  MACD_Hist      float64       \n",
      " 25  Mass_Index     float64       \n",
      " 26  AD             float64       \n",
      " 27  CMF            float64       \n",
      " 28  Force_Index    float64       \n",
      " 29  MFI            float64       \n",
      " 30  OBV            int64         \n",
      " 31  Cum_Return     float64       \n",
      " 32  Cum_Turnover   float64       \n",
      " 33  Hour           float64       \n",
      " 34  Day_Of_Week    float64       \n",
      " 35  Minute_Of_Day  float64       \n",
      "dtypes: datetime64[ns](1), float64(32), int64(3)\n",
      "memory usage: 946.6 MB\n"
     ]
    }
   ],
   "source": [
    "def drop_na_cols(df, threshold=0.01):\n",
    "    cnt = 0\n",
    "    for col in df.columns:\n",
    "        na = df[[col]].isna().sum()\n",
    "        if na.values > len(df) * threshold:\n",
    "            df.drop(col, axis=1, inplace=True)\n",
    "            cnt += 1\n",
    "    print(f'Deleted {cnt} cols')\n",
    "    return df\n",
    "\n",
    "# 6. Hàm xử lý missing values\n",
    "def handle_missing_data(df, threshold=0.01):\n",
    "    df = drop_na_cols(df, threshold)\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    \n",
    "    df = df.bfill().ffill()\n",
    "    df = df.dropna()\n",
    "    \n",
    "    return df\n",
    "\n",
    "# train_df\n",
    "train_df = handle_missing_data(train_df)\n",
    "val_df = handle_missing_data(val_df)\n",
    "test_df = handle_missing_data(test_df)\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T18:36:52.974267Z",
     "iopub.status.busy": "2025-05-26T18:36:52.973846Z",
     "iopub.status.idle": "2025-05-26T18:37:16.105219Z",
     "shell.execute_reply": "2025-05-26T18:37:16.104470Z",
     "shell.execute_reply.started": "2025-05-26T18:36:52.974241Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sử dụng 34 cột đặc trưng: ['Open', 'High', 'Low', 'Close', 'Volume', 'RSI', 'Momentum', 'CMO', 'Williams_%R', 'ATR', 'BB_Mid', 'BB_Upper', 'BB_Lower', 'BB_Bandwidth', 'KC_High', 'KC_Low', 'DC_High', 'DC_Low', 'SMA_20', 'EMA_20', 'DPO', 'MACD', 'MACD_Hist', 'Mass_Index', 'AD', 'CMF', 'Force_Index', 'MFI', 'OBV', 'Cum_Return', 'Cum_Turnover', 'Hour', 'Day_Of_Week', 'Minute_Of_Day']\n",
      "Áp dụng normalize_by_blocks với block_size=128...\n",
      "Hoàn thành normalize_by_blocks. Đã xử lý 26927 khối.\n",
      "Áp dụng normalize_by_blocks với block_size=128...\n",
      "Hoàn thành normalize_by_blocks. Đã xử lý 2743 khối.\n",
      "Áp dụng normalize_by_blocks với block_size=128...\n",
      "Hoàn thành normalize_by_blocks. Đã xử lý 8808 khối.\n"
     ]
    }
   ],
   "source": [
    "def normalize_by_blocks(data, block_size):\n",
    "    print(f\"Áp dụng normalize_by_blocks với block_size={block_size}...\")\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        columns = data.columns\n",
    "        index = data.index\n",
    "        data_np = data.values.astype('float32')\n",
    "    else:\n",
    "        data_np = data.astype('float32')\n",
    "        columns = None\n",
    "        index = None\n",
    "\n",
    "    result = np.zeros_like(data_np)\n",
    "    num_blocks = 0\n",
    "\n",
    "    for start_idx in range(0, len(data_np), block_size):\n",
    "        end_idx = min(start_idx + block_size, len(data_np))\n",
    "        block = data_np[start_idx:end_idx]\n",
    "\n",
    "        if block.shape[0] > 0:\n",
    "            scaler = StandardScaler()\n",
    "            if block.shape[0] == 1:\n",
    "                normalized_block = block - np.mean(block, axis=0)\n",
    "            else:\n",
    "                std_devs = np.std(block, axis=0)\n",
    "                if np.any(std_devs == 0):\n",
    "                    normalized_block = np.zeros_like(block)\n",
    "                    valid_cols = std_devs != 0\n",
    "                    if np.any(valid_cols):\n",
    "                        scaler.fit(block[:, valid_cols])\n",
    "                        normalized_block[:, valid_cols] = scaler.transform(block[:, valid_cols])\n",
    "                    zero_std_cols = std_devs == 0\n",
    "                    if np.any(zero_std_cols):\n",
    "                        normalized_block[:, zero_std_cols] = block[:, zero_std_cols] - np.mean(block[:, zero_std_cols], axis=0)\n",
    "                else:\n",
    "                    normalized_block = scaler.fit_transform(block)\n",
    "\n",
    "            if np.isnan(normalized_block).any() or np.isinf(normalized_block).any():\n",
    "                normalized_block = np.nan_to_num(normalized_block, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "            result[start_idx:end_idx] = normalized_block\n",
    "            num_blocks += 1\n",
    "\n",
    "    print(f\"Hoàn thành normalize_by_blocks. Đã xử lý {num_blocks} khối.\")\n",
    "    if columns is not None and index is not None:\n",
    "        return pd.DataFrame(result, columns=columns, index=index)\n",
    "    else:\n",
    "        return result\n",
    "\n",
    "# Định nghĩa các cột đặc trưng\n",
    "feature_cols = [col for col in train_df.columns if col not in ['Label', 'Datetime']]\n",
    "print(f\"Sử dụng {len(feature_cols)} cột đặc trưng: {feature_cols}\")\n",
    "\n",
    "# Áp dụng chuẩn hóa theo khối\n",
    "BLOCK_SIZE = 128\n",
    "train_df[feature_cols] = normalize_by_blocks(train_df[feature_cols], BLOCK_SIZE)\n",
    "val_df[feature_cols] = normalize_by_blocks(val_df[feature_cols], BLOCK_SIZE)\n",
    "test_df[feature_cols] = normalize_by_blocks(test_df[feature_cols], BLOCK_SIZE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T18:37:16.106222Z",
     "iopub.status.busy": "2025-05-26T18:37:16.105968Z",
     "iopub.status.idle": "2025-05-26T18:37:16.111808Z",
     "shell.execute_reply": "2025-05-26T18:37:16.111137Z",
     "shell.execute_reply.started": "2025-05-26T18:37:16.106204Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Open', 'High', 'Low', 'Close', 'Volume', 'Label', 'Datetime', 'RSI',\n",
       "       'Momentum', 'CMO', 'Williams_%R', 'ATR', 'BB_Mid', 'BB_Upper',\n",
       "       'BB_Lower', 'BB_Bandwidth', 'KC_High', 'KC_Low', 'DC_High', 'DC_Low',\n",
       "       'SMA_20', 'EMA_20', 'DPO', 'MACD', 'MACD_Hist', 'Mass_Index', 'AD',\n",
       "       'CMF', 'Force_Index', 'MFI', 'OBV', 'Cum_Return', 'Cum_Turnover',\n",
       "       'Hour', 'Day_Of_Week', 'Minute_Of_Day'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T18:37:16.114353Z",
     "iopub.status.busy": "2025-05-26T18:37:16.114129Z",
     "iopub.status.idle": "2025-05-26T18:37:16.885231Z",
     "shell.execute_reply": "2025-05-26T18:37:16.884401Z",
     "shell.execute_reply.started": "2025-05-26T18:37:16.114337Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tạo Dataset và DataLoader ---\n",
      "Khởi tạo PreprocessedStockDataset với 34 đặc trưng.\n",
      "Sử dụng 'minute_of_day' cho Time2Vec.\n",
      "Kích thước - Features: (3446549, 34), Labels: (3446549,), Time: (3446549, 1)\n",
      "Khởi tạo PreprocessedStockDataset với 34 đặc trưng.\n",
      "Sử dụng 'minute_of_day' cho Time2Vec.\n",
      "Kích thước - Features: (350984, 34), Labels: (350984,), Time: (350984, 1)\n",
      "Khởi tạo PreprocessedStockDataset với 34 đặc trưng.\n",
      "Sử dụng 'minute_of_day' cho Time2Vec.\n",
      "Kích thước - Features: (1127367, 34), Labels: (1127367,), Time: (1127367, 1)\n"
     ]
    }
   ],
   "source": [
    "class PreprocessedStockDataset(Dataset):\n",
    "    def __init__(self, df, sequence_length, feature_cols, use_time2vec=True):\n",
    "        self.sequence_length = sequence_length\n",
    "        self.feature_cols = [col for col in feature_cols if col in df.columns]\n",
    "        self.use_time2vec = use_time2vec\n",
    "        self.has_time_input = False\n",
    "\n",
    "        print(f\"Khởi tạo PreprocessedStockDataset với {len(self.feature_cols)} đặc trưng.\")\n",
    "        if self.use_time2vec:\n",
    "            if \"Minute_Of_Day\" in df.columns and pd.api.types.is_numeric_dtype(df['Minute_Of_Day']):\n",
    "                print(\"Sử dụng 'minute_of_day' cho Time2Vec.\")\n",
    "                self.time_features = df[\"Minute_Of_Day\"].values[:, np.newaxis].astype(np.float32)\n",
    "                self.has_time_input = True\n",
    "            else:\n",
    "                print(\"Cảnh báo: Không tìm thấy 'minute_of_day'. Time2Vec sẽ dùng giá trị 0.\")\n",
    "                self.time_features = np.zeros((len(df), 1), dtype=np.float32)\n",
    "        else:\n",
    "            self.time_features = np.zeros((len(df), 1), dtype=np.float32)\n",
    "\n",
    "        self.features = df[self.feature_cols].values.astype(np.float32)\n",
    "        if 'Label' in df.columns and pd.api.types.is_numeric_dtype(df['Label']):\n",
    "            self.labels = df['Label'].values.astype(np.int64)\n",
    "            print(f\"Kích thước - Features: {self.features.shape}, Labels: {self.labels.shape}, Time: {self.time_features.shape}\")\n",
    "        else:\n",
    "            print(\"Cảnh báo: Không tìm thấy cột 'Label'. Tạo nhãn giả (0).\")\n",
    "            self.labels = np.zeros(len(df), dtype=np.int64)\n",
    "\n",
    "        if len(self.features) <= self.sequence_length:\n",
    "            raise ValueError(f\"Độ dài DataFrame ({len(self.features)}) phải lớn hơn sequence_length ({self.sequence_length}).\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features) - self.sequence_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        end_idx = idx + self.sequence_length\n",
    "        feat_seq = self.features[idx:end_idx]\n",
    "        time_seq = self.time_features[idx:end_idx]\n",
    "        label = self.labels[end_idx]\n",
    "        return torch.from_numpy(feat_seq).float(), torch.from_numpy(time_seq).float(), torch.tensor(label).long()\n",
    "\n",
    "# Tạo Dataset\n",
    "USE_TIME2VEC = True\n",
    "SEQ_LEN = 128\n",
    "print(\"\\n--- Tạo Dataset và DataLoader ---\")\n",
    "train_dataset = PreprocessedStockDataset(train_df, SEQ_LEN, feature_cols, use_time2vec=USE_TIME2VEC)\n",
    "val_dataset = PreprocessedStockDataset(val_df, SEQ_LEN, feature_cols, use_time2vec=USE_TIME2VEC)\n",
    "test_dataset = PreprocessedStockDataset(test_df, SEQ_LEN, feature_cols, use_time2vec=USE_TIME2VEC)\n",
    "\n",
    "# Tạo DataLoader\n",
    "BATCH_SIZE = 256\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=torch.cuda.is_available())\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE * 2, shuffle=False, num_workers=2, pin_memory=torch.cuda.is_available())\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE * 2, shuffle=False, num_workers=2, pin_memory=torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T18:37:16.886332Z",
     "iopub.status.busy": "2025-05-26T18:37:16.886034Z",
     "iopub.status.idle": "2025-05-26T18:37:17.363514Z",
     "shell.execute_reply": "2025-05-26T18:37:17.362609Z",
     "shell.execute_reply.started": "2025-05-26T18:37:16.886313Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches: 13463\n",
      "Batch input shape: torch.Size([256, 128, 34])\n",
      "Batch times shape: torch.Size([256, 128, 1])\n",
      "Batch labels shape: torch.Size([256])\n",
      "\n",
      "Example input shape for Transformer: torch.Size([128, 34])\n",
      "tensor([[ 0.6224,  0.8578,  0.7255,  ...,  0.9812,  0.0000,  0.7443],\n",
      "        [ 0.5433,  0.2644, -0.0107,  ...,  0.9812,  0.0000,  0.7713],\n",
      "        [-0.3728, -0.6069, -0.3159,  ...,  0.9812,  0.0000,  0.7984],\n",
      "        ...,\n",
      "        [-0.9408, -0.0384, -0.0298,  ...,  0.6713,  0.0000,  0.6631],\n",
      "        [ 0.5465, -0.0837,  0.2351,  ...,  0.6713,  0.0000,  0.6901],\n",
      "        [-0.2076, -0.5815, -2.3689,  ...,  0.6713,  0.0000,  0.7172]])\n"
     ]
    }
   ],
   "source": [
    "# Kiểm tra\n",
    "print(\"Number of batches:\", len(train_loader))\n",
    "sample_batch = next(iter(train_loader))\n",
    "print(\"Batch input shape:\", sample_batch[0].shape)\n",
    "print(\"Batch times shape:\", sample_batch[1].shape)\n",
    "print(\"Batch labels shape:\", sample_batch[2].shape)\n",
    "print(\"\\nExample input shape for Transformer:\", sample_batch[0][0].shape)\n",
    "print(sample_batch[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class InceptionModule(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        self.branch1 = nn.Conv1d(in_channels, 32, kernel_size=1, padding='same')\n",
    "        self.branch3 = nn.Conv1d(in_channels, 32, kernel_size=3, padding='same')\n",
    "        self.branch5 = nn.Conv1d(in_channels, 32, kernel_size=5, padding='same')\n",
    "        self.branch_pool = nn.Sequential(\n",
    "            nn.MaxPool1d(kernel_size=3, stride=1, padding=1),\n",
    "            nn.Conv1d(in_channels, 32, kernel_size=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat([self.branch1(x), self.branch3(x), self.branch5(x), self.branch_pool(x)], dim=1)\n",
    "\n",
    "class Time2Vec(nn.Module):\n",
    "    def __init__(self, time_dim, kernel_dim=32):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(time_dim, 1)\n",
    "        self.periodic = nn.Linear(time_dim, kernel_dim - 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        linear = self.linear(x)\n",
    "        periodic = self.periodic(x)\n",
    "        return torch.cat([linear, periodic], dim=-1)\n",
    "\n",
    "class CrossAttentionFusion(nn.Module):\n",
    "    def __init__(self, cnn_dim, transformer_dim):\n",
    "        super().__init__()\n",
    "        self.query = nn.Linear(cnn_dim, transformer_dim)\n",
    "        self.key = nn.Linear(transformer_dim, transformer_dim)\n",
    "        self.value = nn.Linear(transformer_dim, transformer_dim)\n",
    "        \n",
    "    def forward(self, cnn_features, transformer_features):\n",
    "        Q = self.query(cnn_features).unsqueeze(1)  # [batch, 1, transformer_dim]\n",
    "        K = self.key(transformer_features)         # [batch, seq_len, transformer_dim]\n",
    "        V = self.value(transformer_features)       # [batch, seq_len, transformer_dim]\n",
    "        \n",
    "        attn_scores = (Q @ K.transpose(-2, -1)) / (K.size(-1) ** 0.5)  # [batch, 1, seq_len]\n",
    "        attn_weights = torch.softmax(attn_scores, dim=-1)\n",
    "        \n",
    "        return torch.bmm(attn_weights, V).squeeze(1)  # [batch, transformer_dim]\n",
    "\n",
    "class HighwayNetwork(nn.Module):\n",
    "    def __init__(self, d_model):\n",
    "        super().__init__()\n",
    "        self.gate = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, fused, transformer):\n",
    "        g = self.gate(fused)\n",
    "        return g * fused + (1 - g) * transformer\n",
    "\n",
    "class EnhancedHybridModel(nn.Module):\n",
    "    def __init__(self, num_features, time_dim, num_classes=3, d_model=512, nhead=16, dim_feedforward=1024, num_layers=6):\n",
    "        super().__init__()\n",
    "        # 1. InceptionTime Branch\n",
    "        self.inception = nn.Sequential(\n",
    "            InceptionModule(num_features),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            InceptionModule(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # 2. Transformer Branch\n",
    "        self.time2vec = Time2Vec(time_dim, d_model//2)\n",
    "        self.transformer_proj = nn.Linear(num_features, d_model//2)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward, batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        # 3. Fusion\n",
    "        self.cross_attention = CrossAttentionFusion(128, d_model)\n",
    "        self.highway = HighwayNetwork(d_model)\n",
    "        \n",
    "        # 4. Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(d_model, 128),\n",
    "            nn.LayerNorm(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, time_feature):\n",
    "        # 1. Inception Path\n",
    "        cnn_features = self.inception(x.permute(0, 2, 1))  # [batch, channels, seq_len//2]\n",
    "        cnn_features = cnn_features.mean(dim=-1)          # [batch, channels=128]\n",
    "        \n",
    "        # 2. Transformer Path\n",
    "        time_embed = self.time2vec(time_feature)  # [batch, seq_len, d_model // 2]\n",
    "        x_proj = self.transformer_proj(x)  # [batch, seq_len, d_model // 2]\n",
    "        combined = torch.cat([time_embed, x_proj], dim=-1) # [batch, seq_len, d_model]\n",
    "        transformer_features = self.transformer(combined)  # [batch, seq_len, d_model]\n",
    "        \n",
    "        # 3. Fusion\n",
    "        fused = self.cross_attention(cnn_features, transformer_features)  # [batch, d_model]\n",
    "        output = self.highway(fused, transformer_features.mean(dim=1))   # [batch, d_model]\n",
    "        \n",
    "        return self.classifier(output)\n",
    "\n",
    "N_FEATURES = sample_batch[0].shape[-1]\n",
    "model = EnhancedHybridModel(\n",
    "    num_features=N_FEATURES, time_dim=1, num_classes=3, \n",
    "    d_model=128, nhead=8, dim_feedforward=256, num_layers=3\n",
    ")\n",
    "\n",
    "model.load_state_dict(torch.load('save/models/used_model.pth', weights_only=True, map_location='cpu'))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7055460,
     "sourceId": 11294529,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 358116,
     "modelInstanceId": 337140,
     "sourceId": 413002,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
